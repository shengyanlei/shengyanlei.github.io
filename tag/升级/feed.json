{
    "version": "https://jsonfeed.org/version/1",
    "title": "碎念随风 • All posts by \"升级\" tag",
    "description": "人海未见之时，我亦独行在这城市。 料峭，春醒，酷暑，骤雨，寒意四起，大雁南飞，而后，大雪，寒风， 斗转星移，人间寒暑。",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/11/16/BaiduSyncdisk/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/hive3-13%E6%B7%BB%E5%8A%A0spark%E5%BC%95%E6%93%8E/",
            "url": "http://example.com/2023/11/16/BaiduSyncdisk/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/hive3-13%E6%B7%BB%E5%8A%A0spark%E5%BC%95%E6%93%8E/",
            "title": "hive3.13添加spark引擎",
            "date_published": "2023-11-16T02:39:42.000Z",
            "content_html": "<p><em><strong>大数据架构 :lambda 架构，hsap 架构，流批一体</strong></em></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9jd2lraS5hcGFjaGUub3JnL2NvbmZsdWVuY2UvZGlzcGxheS9IaXZlL0hpdmUrb24rU3BhcmslM0ErR2V0dGluZytTdGFydGVk\">Hive 官网关于 spark on hive</span></p>\n<h3 id=\"一-spark-on-hive-和-hive-on-spark-的区别和联系\"><a class=\"markdownIt-Anchor\" href=\"#一-spark-on-hive-和-hive-on-spark-的区别和联系\">#</a> 一、spark on hive 和 hive on spark 的区别和联系</h3>\n<p><em><strong>spark on hive</strong></em>：Spark on Hive 是 Hive 只作为存储角色，Spark 负责 sql 解析优化，执行</p>\n<p><em><strong>hive on spark：</strong></em></p>\n<h3 id=\"二-版本选择\"><a class=\"markdownIt-Anchor\" href=\"#二-版本选择\">#</a> 二、版本选择</h3>\n<p>要在 Hive 3.1.3 中更换为 Spark 2.3 引擎，您需要按照以下步骤进行配置：</p>\n<ol>\n<li>\n<p><strong>下载并安装 Spark 2.3</strong>：</p>\n<ul>\n<li>从 Apache Spark 官网下载 Spark 2.3.3 版本，并解压到指定目录。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">tar</span> <span class=\"token parameter variable\">-zxvf</span> spark-2.3.3-bin-without-hadoop.tgz <span class=\"token parameter variable\">-C</span> /opt/module/</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">mv</span> /opt/module/spark-2.3.3-bin-without-hadoop /opt/module/spark-2.3.0</pre></td></tr></table></figure><ul>\n<li>配置 <code>SPARK_HOME</code>  环境变量。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">vim</span> /etc/profile.d/my_env.sh</pre></td></tr></table></figure><p>添加以下内容：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># SPARK_HOME</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">SPARK_HOME</span><span class=\"token operator\">=</span>/opt/module/spark-2.3.0</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token variable\">$SPARK_HOME</span>/bin</pre></td></tr></table></figure><p>然后，使环境变量生效：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">source</span> /etc/profile.d/my_env.sh</pre></td></tr></table></figure></li>\n<li>\n<p><strong>配置 Hive 以使用 Spark 作为执行引擎</strong>：</p>\n<ul>\n<li>修改 <code>hive-site.xml</code>  文件，添加以下内容：</li>\n</ul>\n<figure class=\"highlight xml\"><figcaption data-lang=\"XML\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>hive.execution.engine<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>spark<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr></table></figure><ul>\n<li>指定 Spark 的 jar 包位置（注意：端口号 8020 必须和 namenode 的端口号一致）：</li>\n</ul>\n<figure class=\"highlight xml\"><figcaption data-lang=\"XML\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>spark.yarn.jars<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>hdfs://hadoop102:8020/spark-jars/*<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>上传 Spark 的 jar 包至 HDFS</strong>：</p>\n<ul>\n<li>将 Spark 的 jar 包上传到 HDFS 的指定目录：</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>hdfs dfs <span class=\"token parameter variable\">-mkdir</span> <span class=\"token parameter variable\">-p</span> /spark-jars</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>hdfs dfs <span class=\"token parameter variable\">-put</span> /opt/module/spark/jars/* /spark-jars/</pre></td></tr></table></figure></li>\n<li>\n<p><strong>测试 Hive on Spark</strong>：</p>\n<ul>\n<li>启动 Hive 客户端并执行一些测试查询以确保 Spark 作为执行引擎正常工作。</li>\n</ul>\n</li>\n</ol>\n<p><img data-src=\"https://note.youdao.com/yws/api/personal/file/WEBbae2c251f4135b4211f8586212d00c3b?method=download&amp;shareKey=8f2f03de469097c4b137501a257214cc\" alt=\"查询验证\"></p>\n<p><img data-src=\"https://note.youdao.com/yws/api/personal/file/WEBea630c8b4ed974f7ccc9ca09a5f90865?method=download&amp;shareKey=8025360ba19b11bfcabd229bc0f0e2f1\" alt=\"引擎查询\"></p>\n",
            "tags": [
                "升级"
            ]
        }
    ]
}