{
    "version": "https://jsonfeed.org/version/1",
    "title": "碎念随风 • All posts by \"hive\" category",
    "description": "人海未见之时，我亦独行在这城市。 料峭，春醒，酷暑，骤雨，寒意四起，大雁南飞，而后，大雪，寒风， 斗转星移，人间寒暑。",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/11/16/BaiduSyncdisk/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/hive3-13%E6%B7%BB%E5%8A%A0spark%E5%BC%95%E6%93%8E/",
            "url": "http://example.com/2023/11/16/BaiduSyncdisk/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/hive3-13%E6%B7%BB%E5%8A%A0spark%E5%BC%95%E6%93%8E/",
            "title": "hive3.13添加spark引擎",
            "date_published": "2023-11-16T02:39:42.000Z",
            "content_html": "<p><em><strong>大数据架构 :lambda 架构，hsap 架构，流批一体</strong></em></p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9jd2lraS5hcGFjaGUub3JnL2NvbmZsdWVuY2UvZGlzcGxheS9IaXZlL0hpdmUrb24rU3BhcmslM0ErR2V0dGluZytTdGFydGVk\">Hive 官网关于 spark on hive</span></p>\n<h3 id=\"一-spark-on-hive-和-hive-on-spark-的区别和联系\"><a class=\"markdownIt-Anchor\" href=\"#一-spark-on-hive-和-hive-on-spark-的区别和联系\">#</a> 一、spark on hive 和 hive on spark 的区别和联系</h3>\n<p><em><strong>spark on hive</strong></em>：Spark on Hive 是 Hive 只作为存储角色，Spark 负责 sql 解析优化，执行</p>\n<p><em><strong>hive on spark：</strong></em></p>\n<h3 id=\"二-版本选择\"><a class=\"markdownIt-Anchor\" href=\"#二-版本选择\">#</a> 二、版本选择</h3>\n<p>要在 Hive 3.1.3 中更换为 Spark 2.3 引擎，您需要按照以下步骤进行配置：</p>\n<ol>\n<li>\n<p><strong>下载并安装 Spark 2.3</strong>：</p>\n<ul>\n<li>从 Apache Spark 官网下载 Spark 2.3.3 版本，并解压到指定目录。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">tar</span> <span class=\"token parameter variable\">-zxvf</span> spark-2.3.3-bin-without-hadoop.tgz <span class=\"token parameter variable\">-C</span> /opt/module/</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">mv</span> /opt/module/spark-2.3.3-bin-without-hadoop /opt/module/spark-2.3.0</pre></td></tr></table></figure><ul>\n<li>配置 <code>SPARK_HOME</code>  环境变量。</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">vim</span> /etc/profile.d/my_env.sh</pre></td></tr></table></figure><p>添加以下内容：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># SPARK_HOME</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">SPARK_HOME</span><span class=\"token operator\">=</span>/opt/module/spark-2.3.0</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token variable\">$SPARK_HOME</span>/bin</pre></td></tr></table></figure><p>然后，使环境变量生效：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">source</span> /etc/profile.d/my_env.sh</pre></td></tr></table></figure></li>\n<li>\n<p><strong>配置 Hive 以使用 Spark 作为执行引擎</strong>：</p>\n<ul>\n<li>修改 <code>hive-site.xml</code>  文件，添加以下内容：</li>\n</ul>\n<figure class=\"highlight xml\"><figcaption data-lang=\"XML\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>hive.execution.engine<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>spark<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr></table></figure><ul>\n<li>指定 Spark 的 jar 包位置（注意：端口号 8020 必须和 namenode 的端口号一致）：</li>\n</ul>\n<figure class=\"highlight xml\"><figcaption data-lang=\"XML\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>spark.yarn.jars<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>hdfs://hadoop102:8020/spark-jars/*<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>上传 Spark 的 jar 包至 HDFS</strong>：</p>\n<ul>\n<li>将 Spark 的 jar 包上传到 HDFS 的指定目录：</li>\n</ul>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>hdfs dfs <span class=\"token parameter variable\">-mkdir</span> <span class=\"token parameter variable\">-p</span> /spark-jars</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>hdfs dfs <span class=\"token parameter variable\">-put</span> /opt/module/spark/jars/* /spark-jars/</pre></td></tr></table></figure></li>\n<li>\n<p><strong>测试 Hive on Spark</strong>：</p>\n<ul>\n<li>启动 Hive 客户端并执行一些测试查询以确保 Spark 作为执行引擎正常工作。</li>\n</ul>\n</li>\n</ol>\n<p><img data-src=\"https://note.youdao.com/yws/api/personal/file/WEBbae2c251f4135b4211f8586212d00c3b?method=download&amp;shareKey=8f2f03de469097c4b137501a257214cc\" alt=\"查询验证\"></p>\n<p><img data-src=\"https://note.youdao.com/yws/api/personal/file/WEBea630c8b4ed974f7ccc9ca09a5f90865?method=download&amp;shareKey=8025360ba19b11bfcabd229bc0f0e2f1\" alt=\"引擎查询\"></p>\n",
            "tags": [
                "升级"
            ]
        },
        {
            "id": "http://example.com/2023/11/03/BaiduSyncdisk/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/Hive%E4%B8%AD%E7%9A%84explode/",
            "url": "http://example.com/2023/11/03/BaiduSyncdisk/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/Hive%E4%B8%AD%E7%9A%84explode/",
            "title": "Hive中的explode",
            "date_published": "2023-11-03T02:22:29.000Z",
            "content_html": "<h3 id=\"一-问题介绍\"><a class=\"markdownIt-Anchor\" href=\"#一-问题介绍\">#</a> 一、问题介绍</h3>\n<p>在使用 explode 进行炸列操作时，发现炸列后有的行消失了。</p>\n<h3 id=\"二-模拟场景\"><a class=\"markdownIt-Anchor\" href=\"#二-模拟场景\">#</a> 二、模拟场景</h3>\n<pre><code class=\"language-hive\">建表语句\ndrop table test.shyl_explode_test;\ncreate table test.shyl_explode_test(\n    `id` string comment 'id',\n    `list` ARRAY&lt;string&gt; comment '列表'\n)comment'测试炸列函数所使用的字段为空时，该行数据如何处理'\nstored as orc;\n插入数据\nINSERT INTO TABLE shyl_explode_test VALUES\n  ('1', array('A', 'B', 'C')),\n  ('2', array('X', 'Y')),\n  ('3', array(&quot;&quot;))\n  ('4', null)\n  ('5', array(null));\n</code></pre>\n<p>当插入数据 (‘4’, null) 报错 <code>[42000][40000] Error while compiling statement: FAILED: SemanticException 0:0 Expected 2 columns for insclause-0/test@shyl_explode_test; select produces 1 columns. Error encountered near token 'TOK_NULL'</code></p>\n<p>大概的意思是说这个 list 字段的数据类型是 array，现在要插入一个 null 类型的，类型不匹配，</p>\n<p>但是在实际情况中，表中数据类型为 array，其值为 null 的情况不少见，比如我们是通过上传文件到 hdfs，再通过 hive 建表关联数据，得到的表【具体过程没有验证，不确定是是否可以创建成功】；执行连接操作时，没有关联上的使用 null 填充【未验证】; 或者只插入一个列的值，【本文就采取这种方式】，得到 list 字段为空的情况：</p>\n<pre><code class=\"language-HIVE\">INSERT INTO TABLE shyl_explode_test(id) VALUES ('4');\n</code></pre>\n<pre><code class=\"language-hive\">查看表中的数据\nselect * from test.shyl_explode_test;\n</code></pre>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">id</th>\n<th style=\"text-align:left\">list</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">[“A”,“B”,“C”]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">[“X”,“Y”]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">[&quot;&quot;]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">4</td>\n<td style=\"text-align:left\">null</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">5</td>\n<td style=\"text-align:left\">[null]</td>\n</tr>\n</tbody>\n</table>\n<pre><code class=\"language-hive\">现根据list字段为null，查询出指定数据\nselect * from test.shyl_explode_test where list is null;\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>list</th>\n</tr>\n</thead>\n</table>\n<p>发现数据为空，原因可能与字段类型为 array 有关</p>\n<p>现提供一个其它的方式查询</p>\n<pre><code class=\"language-hive\">因为size(map/array)返回 -1 作为特殊的值，通常表示一个无效或异常的情况，而不是实际的大小或长度,所以利用它来查询空值\nselect size(null);\n-1\nselect * from test.shyl_explode_test where size(list)=-1;\n</code></pre>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">id</th>\n<th style=\"text-align:left\">list</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">4</td>\n<td style=\"text-align:left\">null</td>\n</tr>\n</tbody>\n</table>\n<p>有关 sql 中的 null 参考此文：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC84MjQzNDAyNA==\">原文地址</span></p>\n<h3 id=\"三-执行explode\"><a class=\"markdownIt-Anchor\" href=\"#三-执行explode\">#</a> 三、执行 explode</h3>\n<pre><code>select * from test.shyl_explode_test\nlateral view explode(list)t1 as a;\n</code></pre>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">id</th>\n<th style=\"text-align:left\">list</th>\n<th style=\"text-align:left\">a</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">[“A”,“B”,“C”]</td>\n<td style=\"text-align:left\">A</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">[“A”,“B”,“C”]</td>\n<td style=\"text-align:left\">B</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">[“A”,“B”,“C”]</td>\n<td style=\"text-align:left\">C</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">[“X”,“Y”]</td>\n<td style=\"text-align:left\">X</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">[“X”,“Y”]</td>\n<td style=\"text-align:left\">Y</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">[&quot;&quot;]</td>\n<td style=\"text-align:left\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">5</td>\n<td style=\"text-align:left\">[null]</td>\n<td style=\"text-align:left\">null</td>\n</tr>\n</tbody>\n</table>\n<p>我们发现 id 为 4 的那一行数据缺失，现在是有两列，当我的列数多，且其它列的数据重要时，会发生丢失一些重要数据的情况。</p>\n<p>所以在执行 explode 的时候添加一些保护机制，附上一些不影响结果的默认值。</p>\n<pre><code class=\"language-hive\">select * from test.shyl_explode_test\nlateral view explode(nvl(list,array(NULL)))t1 as a;\n</code></pre>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">id</th>\n<th style=\"text-align:left\">list</th>\n<th style=\"text-align:left\">a</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">[“A”,“B”,“C”]</td>\n<td style=\"text-align:left\">A</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">[“A”,“B”,“C”]</td>\n<td style=\"text-align:left\">B</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">[“A”,“B”,“C”]</td>\n<td style=\"text-align:left\">C</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">[“X”,“Y”]</td>\n<td style=\"text-align:left\">X</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">[“X”,“Y”]</td>\n<td style=\"text-align:left\">Y</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">[&quot;&quot;]</td>\n<td style=\"text-align:left\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><font style=\"color:red\">4</font></td>\n<td style=\"text-align:left\"><font style=\"color:red\">null</font></td>\n<td style=\"text-align:left\"><font style=\"color:red\">null</font></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">5</td>\n<td style=\"text-align:left\">[null]</td>\n<td style=\"text-align:left\">null</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"四-explodelateral-view源码剖析\"><a class=\"markdownIt-Anchor\" href=\"#四-explodelateral-view源码剖析\">#</a> 四、explode+lateral view 源码剖析</h3>\n<p>【目前不会看源码】，之后有能力补上，从结果反推，像是炸列后执行的 inner join。</p>\n",
            "tags": [
                "Bug"
            ]
        },
        {
            "id": "http://example.com/2023/11/03/BaiduSyncdisk/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/Hive%E4%B8%AD%E7%9A%84Struct%E7%B1%BB%E5%9E%8BBug/",
            "url": "http://example.com/2023/11/03/BaiduSyncdisk/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/Hive%E4%B8%AD%E7%9A%84Struct%E7%B1%BB%E5%9E%8BBug/",
            "title": "Hive中的Struct类型Bug",
            "date_published": "2023-11-03T02:21:17.000Z",
            "content_html": "<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9ISVZFLTIxNzc4\">原文地址</span></p>\n<h3 id=\"一-hive的struct类型介绍\"><a class=\"markdownIt-Anchor\" href=\"#一-hive的struct类型介绍\">#</a> 一、hive 的 Struct 类型介绍</h3>\n<p>Struct 是 Hive 复杂数据类型的一种 ，声明方式  <code>STRUCT&lt;col_name : data_type [COMMENT col_comment], ...&gt;</code></p>\n<h3 id=\"二-cbo介绍\"><a class=\"markdownIt-Anchor\" href=\"#二-cbo介绍\">#</a> 二、CBO 介绍</h3>\n<h3 id=\"三-解决方式\"><a class=\"markdownIt-Anchor\" href=\"#三-解决方式\">#</a> 三、解决方式</h3>\n",
            "tags": [
                "Bug"
            ]
        }
    ]
}